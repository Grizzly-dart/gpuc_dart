+ Tensor.rearrange in C and CUDA (pytorch.permute)
+ Test with complex math equation to optimize intermediate results
+ Split C library into C and CUDA
+ Better print Tensors as tables
+ MaxPool2D return indices
+ tensor.json read and write

# Layers
+ MaxPool2D
+ Group normalization
+ Conv2D
+ ResNet

# Multi device
+ Test seamless switching between devices

# Low prio
+ ROCm implementation
+ SYCL implementation

# Decisions

+ Should GPU operations be async-await?